{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import pickle\n",
    "from scipy.signal import welch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Masking\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "data_dir = \"preprocessed_epochs\"\n",
    "frequency_bands = {\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 13),\n",
    "    \"beta\": (13, 30),\n",
    "}\n",
    "\n",
    "# region_channels = {\n",
    "#     \"frontal\": [\"Fp1\", \"Fp2\", \"Fz\", \"F3\", \"F4\"],\n",
    "#     \"central\": [\"Cz\", \"C3\", \"C4\"],\n",
    "#     \"parietal\": [\"Pz\", \"P3\", \"P4\"],\n",
    "#     \"occipital\": [\"O1\", \"O2\"],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [] \n",
    "y_data = [] \n",
    "max_epochs = 75  \n",
    "\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if not file_name.endswith(\".fif\"):\n",
    "        continue  \n",
    "\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    epochs = mne.read_epochs(file_path, preload=True)\n",
    "\n",
    "    if len(epochs) < 10:\n",
    "        print(f\"Skipping patient {file_name}: less than 10 epochs.\")\n",
    "        continue\n",
    "\n",
    "    patient_data = epochs.get_data()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    n_epochs, n_channels, n_times = patient_data.shape\n",
    "\n",
    "    patient_data = patient_data.reshape(n_epochs, -1) \n",
    "    normalized_data = scaler.fit_transform(patient_data) \n",
    "    normalized_data = normalized_data.reshape(n_epochs, n_channels, n_times)  \n",
    "\n",
    "    X_data.append(normalized_data)\n",
    "    y_data.append(1 if \"ses-2\" in file_name else 0)  \n",
    "\n",
    "# Padding\n",
    "X_padded = []\n",
    "for patient_data in X_data:\n",
    "    num_epochs = len(patient_data)\n",
    "    if num_epochs > max_epochs:\n",
    "        # Truncate\n",
    "        padded_data = patient_data[:max_epochs]\n",
    "    else:\n",
    "        padded_data = np.pad(\n",
    "            patient_data,\n",
    "            ((0, max_epochs - num_epochs), (0, 0), (0, 0)),  \n",
    "            mode=\"constant\",\n",
    "            constant_values=0\n",
    "        )\n",
    "    X_padded.append(padded_data)\n",
    "\n",
    "X_padded = np.array(X_padded) \n",
    "y_data = np.array(y_data)  \n",
    "save_path = \"RNN_padded_data\"\n",
    "with open(save_path, \"wb\") as file:\n",
    "    pickle.dump((X_padded, y_data), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'RNN_padded_data'\n",
    "with open(save_path, \"rb\") as file:\n",
    "    X_padded, y_data = pickle.load(file)\n",
    "\n",
    "test_patients_sd = [\"52\", \"18\", \"29\", \"17\", \"34\"]\n",
    "test_patients_ns = [\"01\", \"19\", \"30\", \"65\", \"10\"]\n",
    "validate_patients_sd = [\"55\", \"10\", \"22\", \"68\", \"19\", \"42\", \"63\", \"14\"]\n",
    "validate_patients_ns = [\"13\", \"25\", \"69\", \"24\", \"33\", \"38\", \"67\", \"34\"]\n",
    "\n",
    "test_sessions = [(patient, \"2\") for patient in test_patients_sd] + [(patient, \"1\") for patient in test_patients_ns]\n",
    "validate_sessions = [(patient, \"2\") for patient in validate_patients_sd] + [(patient, \"1\") for patient in validate_patients_ns]\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_val, y_val = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "\n",
    "X_padded_reshaped = X_padded.reshape(-1, X_padded.shape[3], X_padded.shape[2])  \n",
    "y_data_repeated = np.repeat(y_data, X_padded.shape[1])  \n",
    "\n",
    "\n",
    "all_file_names = [\n",
    "    file_name for file_name in os.listdir(data_dir) if file_name.endswith(\".fif\")\n",
    "]\n",
    "\n",
    "X_padded_reshaped = X_padded.reshape(-1, X_padded.shape[3], X_padded.shape[2])  \n",
    "y_data_repeated = np.repeat(y_data, X_padded.shape[1])  \n",
    "\n",
    "test_patient_data = []\n",
    "validate_patient_data = []\n",
    "train_patient_data = []\n",
    "\n",
    "for file_name, (epoch_data, label) in zip(all_file_names, zip(X_padded_reshaped, y_data_repeated)):\n",
    "    patient_id, session_info = file_name.split(\"_\")[0].split(\"-\")[1], file_name.split(\"_\")[1].split(\"-\")[1]\n",
    "\n",
    "    if (patient_id, session_info) in test_sessions:\n",
    "        X_test.extend(epoch_data) \n",
    "        y_test.extend([1 if session_info == '2' else 0] * len(epoch_data)) \n",
    "        test_patient_data.append({\n",
    "            \"features\": epoch_data,  \n",
    "            \"label\": 1 if session_info == '2' else 0  \n",
    "        })\n",
    "    elif (patient_id, session_info) in validate_sessions:\n",
    "        X_val.extend(epoch_data)  \n",
    "        y_val.extend([1 if session_info == '2' else 0] * len(epoch_data))  \n",
    "        validate_patient_data.append({\n",
    "            \"features\": epoch_data,  \n",
    "            \"label\": 1 if session_info == '2' else 0  \n",
    "        })\n",
    "    else:\n",
    "        X_train.extend(epoch_data)  \n",
    "        y_train.extend([1 if session_info == '2' else 0] * len(epoch_data))\n",
    "        train_patient_data.append({\n",
    "            \"features\": epoch_data,  \n",
    "            \"label\": 1 if session_info == '2' else 0  \n",
    "        })\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "epochs = 40  \n",
    "input_shape = (X_train.shape[1], X_train.shape[2]) \n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=0,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "def build_gru_model(input_shape, gru_units, dropouts):\n",
    "    model = Sequential([\n",
    "        Masking(mask_value=0.0, input_shape=input_shape),\n",
    "        GRU(units=gru_units, return_sequences=True, dropout=dropouts, use_cudnn=False),\n",
    "        GRU(units=gru_units // 2, return_sequences=True, dropout=dropouts, use_cudnn=False),\n",
    "        GRU(units=gru_units // 4, return_sequences=False, dropout=dropouts, use_cudnn=False),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=1, activation='sigmoid'),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    gru_units = trial.suggest_int('gru_units', 64, 512, step=64)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "    dropouts = trial.suggest_float('dropouts', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "\n",
    "    model = build_gru_model(input_shape, gru_units, dropouts)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=40,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    return val_accuracy  \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  \n",
    "study.trials_dataframe().to_csv(\"optuna_study_results.csv\")\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "best_params = study.best_params\n",
    "gru_units = best_params['gru_units']\n",
    "learning_rate = best_params['learning_rate']\n",
    "dropouts = best_params['dropouts']\n",
    "batch_size = best_params['batch_size']\n",
    "\n",
    "model = build_gru_model(input_shape, gru_units, dropouts)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=batch_size,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy (Epoch-Level): {test_accuracy:.4f}\")\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\nEpoch-Level Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_binary, target_names=[\"Normal Sleep\", \"Sleep Deprivation\"]))\n",
    "\n",
    "conf_matrix_epoch = confusion_matrix(y_test, y_test_pred_binary)\n",
    "print(\"\\nEpoch-Level Confusion Matrix:\")\n",
    "print(conf_matrix_epoch)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix_epoch, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Normal Sleep\", \"Sleep Deprivation\"],\n",
    "            yticklabels=[\"Normal Sleep\", \"Sleep Deprivation\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Epoch-Level Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "session_predictions = []\n",
    "session_labels = []\n",
    "start_idx = 0\n",
    "\n",
    "for data in test_patient_data:\n",
    "    num_epochs = data[\"features\"].shape[0]\n",
    "    session_pred = y_test_pred_binary[start_idx:start_idx + num_epochs]  \n",
    "    session_label = data[\"label\"]\n",
    "    \n",
    "    majority_label = Counter(session_pred).most_common(1)[0][0]\n",
    "    session_predictions.append(majority_label)\n",
    "    session_labels.append(session_label)\n",
    "    \n",
    "    start_idx += num_epochs\n",
    "\n",
    "session_accuracy = accuracy_score(session_labels, session_predictions)\n",
    "print(f\"\\nSession-Level Accuracy: {session_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nSession-Level Classification Report:\")\n",
    "print(classification_report(session_labels, session_predictions, target_names=[\"Normal Sleep\", \"Sleep Deprivation\"]))\n",
    "\n",
    "conf_matrix_session = confusion_matrix(session_labels, session_predictions)\n",
    "print(\"\\nSession-Level Confusion Matrix:\")\n",
    "print(conf_matrix_session)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix_session, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Normal Sleep\", \"Sleep Deprivation\"],\n",
    "            yticklabels=[\"Normal Sleep\", \"Sleep Deprivation\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Session-Level Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_padded.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
