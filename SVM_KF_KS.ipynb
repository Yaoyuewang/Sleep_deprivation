{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from pykalman import KalmanFilter\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.signal import welch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# test patients \n",
    "data_dir = \"preprocessed_epochs\"\n",
    "test_patients_sd = [\"52\", \"18\", \"29\", \"17\", \"34\", \"55\",\"10\", \"22\", \"68\", \"19\", \"42\", \"63\"]\n",
    "test_patients_ns = [\"01\", \"19\", \"30\", \"65\", \"10\", \"13\", \"25\", \"69\", \"24\", \"33\", \"38\", \"67\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sessions = []\n",
    "for patient in test_patients_ns:\n",
    "    test_sessions.append((patient, \"1\"))\n",
    "for patient in test_patients_sd:\n",
    "    test_sessions.append((patient, \"2\"))\n",
    "\n",
    "def process_epoch_em(epoch, n_components, n_iter):\n",
    "    \"\"\"\n",
    "    Apply PCA to reduce dimensionality, then use Kalman Filter with EM to estimate parameters.\n",
    "    \"\"\"\n",
    "    # Apply PCA (variance percentage?)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_epoch = pca.fit_transform(epoch.T)  \n",
    "    kf = KalmanFilter(\n",
    "        transition_matrices=np.eye(n_components),  # Initial guess for transition matrix\n",
    "        observation_matrices=np.eye(n_components), \n",
    "        transition_covariance=np.eye(n_components) * 1e-4,  # Small regularization, did not converge without this \n",
    "        observation_covariance=np.eye(n_components) * 1e-4 \n",
    "    )\n",
    "\n",
    "    kf = kf.em(reduced_epoch, n_iter=n_iter)\n",
    "\n",
    "    smoothed_state_means, _ = kf.smooth(reduced_epoch)\n",
    "    return smoothed_state_means.T  \n",
    "\n",
    "smoothed_data_dict = {}\n",
    "\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if not file_name.endswith(\".fif\"):\n",
    "        continue\n",
    "\n",
    "    patient_id = file_name.split(\"_\")[0].split(\"-\")[1]\n",
    "    session = file_name.split(\"_\")[1].split(\"-\")[1]\n",
    "\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    epochs = mne.read_epochs(file_path, preload=True)\n",
    "\n",
    "    # skip patients with less than 10 epochs, too little data, may skew results \n",
    "    if len(epochs) < 10:\n",
    "        continue\n",
    "\n",
    "    # parallel\n",
    "    smoothed_epochs = Parallel(n_jobs=14)(\n",
    "        delayed(process_epoch_em)(epoch, n_components = 25, n_iter=7) for epoch in epochs.get_data()\n",
    "    )\n",
    "\n",
    "    smoothed_data_dict[f\"{patient_id}_ses-{session}\"] = {\n",
    "        \"smoothed_data\": np.array(smoothed_epochs), \n",
    "        \"label\": 0 if session == \"1\" else 1  # 0 = NS, 1 = SD\n",
    "    }\n",
    "\n",
    "    smoothed_data = np.array(smoothed_epochs)  \n",
    "    print(f\"Processed {file_name}: {smoothed_data.shape}\")\n",
    "\n",
    "output_file = \"KF_smoothed_data.pkl\"\n",
    "with open(output_file, \"wb\") as f:\n",
    "    pickle.dump(smoothed_data_dict, f)\n",
    "\n",
    "print(f\"Saved smoothed data to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACTING FEATURES\n",
    "frequency_bands = {\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 13),\n",
    "    \"beta\": (13, 30),\n",
    "}\n",
    "\n",
    "features_file = \"KF_smoothed_data.pkl\"\n",
    "\n",
    "with open(features_file, 'rb') as f:\n",
    "    smoothed_data_dict = pickle.load(f)\n",
    "\n",
    "patient_features_dict = {}\n",
    "sfreq = 500\n",
    "# feature extraction is similar in each one, just change a little bit based on the input to ML \n",
    "for patient_session, data in smoothed_data_dict.items():\n",
    "    smoothed_data = data[\"smoothed_data\"]  \n",
    "    label = data[\"label\"]\n",
    "    n_epochs, n_components, n_timepoints = smoothed_data.shape\n",
    "\n",
    "    band_power_features = {band: [] for band in frequency_bands}\n",
    "    temporal_features = []\n",
    "    for epoch in smoothed_data:  \n",
    "        freqs, psd = welch(epoch, sfreq, nperseg=sfreq * 2, axis=1)  \n",
    "\n",
    "        for band_name, (fmin, fmax) in frequency_bands.items():\n",
    "            band_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "            band_power = psd[:, band_mask].mean(axis=1)  \n",
    "            band_power_features[band_name].append(band_power)\n",
    "        \n",
    "        mean_features = np.mean(epoch, axis=1) \n",
    "        variance_features = np.var(epoch, axis=1)\n",
    "        temporal_features.append(np.hstack([mean_features, variance_features]))\n",
    "    for band_name in frequency_bands:\n",
    "        band_power_features[band_name] = np.array(band_power_features[band_name]) \n",
    "\n",
    "    theta_power = band_power_features[\"theta\"]\n",
    "    alpha_power = band_power_features[\"alpha\"]\n",
    "    beta_power = band_power_features[\"beta\"]\n",
    "\n",
    "    theta_alpha_ratio = theta_power / (alpha_power + 1e-10)\n",
    "    theta_beta_ratio = theta_power / (beta_power + 1e-10)\n",
    "    alpha_beta_ratio = alpha_power / (beta_power + 1e-10)\n",
    "   \n",
    "    temporal_features = np.array(temporal_features)\n",
    "    \n",
    "    all_features = np.hstack([theta_power, alpha_power, beta_power, theta_beta_ratio, alpha_beta_ratio, theta_alpha_ratio, temporal_features])\n",
    "    patient_id, session = patient_session.split(\"_\")  \n",
    "    unique_patient_id = f\"{patient_id}_{session}\"\n",
    "\n",
    "    patient_features_dict[unique_patient_id] = {\n",
    "    \"features\": all_features,\n",
    "    \"label\": label,\n",
    "    }   \n",
    "output_file = \"KF_extracted_features.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(patient_features_dict, f)\n",
    "\n",
    "print(f\"Saved extracted features to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL AND LEAVE 2 PATIENT OUT FOLD \n",
    "from collections import Counter\n",
    "features_file = \"KF_extracted_features.pkl\"\n",
    "\n",
    "with open(features_file, 'rb') as f:\n",
    "    patient_features_dict = pickle.load(f)\n",
    "\n",
    "pairs = list(zip(test_patients_ns, test_patients_sd))\n",
    "\n",
    "#loop through different svm configs, to see which one is the best \n",
    "svm_configs = [\n",
    "    {\"kernel\": \"linear\", \"C\": 1.0, \"class_weight\": \"balanced\"},\n",
    "    {\"kernel\": \"rbf\", \"C\": 1.0, \"gamma\": \"scale\", \"class_weight\": \"balanced\"},\n",
    "    {\"kernel\": \"poly\", \"C\": 1.0, \"degree\": 3, \"class_weight\": \"balanced\"},\n",
    "    {\"kernel\": \"sigmoid\", \"C\": 1.0, \"class_weight\": \"balanced\"}\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for config in svm_configs:\n",
    "    print(f\"\\nEvaluating SVM with configuration: {config}\")\n",
    "    \n",
    "    total_correct_sessions = 0\n",
    "    total_correct_epochs = 0\n",
    "    total_sessions = len(test_patients_ns) + len(test_patients_sd)\n",
    "    total_epochs = 0\n",
    "    for fold, (ns_patient, sd_patient) in enumerate(pairs):\n",
    "        train_features = []\n",
    "        train_labels = []\n",
    "        test_features = []\n",
    "        test_labels = []\n",
    "        test_patient_data = []\n",
    "\n",
    "        for unique_patient_session, data in patient_features_dict.items():\n",
    "            patient_id, session = unique_patient_session.split(\"_\")\n",
    "\n",
    "            # Skip the test patients \n",
    "            if (patient_id == ns_patient and session == \"ses-1\") or (patient_id == sd_patient and session == \"ses-2\"):\n",
    "                test_features.append(data[\"features\"])  \n",
    "                num_epochs = data[\"features\"].shape[0]  \n",
    "                test_labels.extend([data[\"label\"]] * num_epochs) \n",
    "                test_patient_data.append(data)\n",
    "                continue\n",
    "            \n",
    "            train_features.append(data[\"features\"])\n",
    "            num_epochs = data[\"features\"].shape[0] \n",
    "            train_labels.extend([data[\"label\"]] * num_epochs)\n",
    "\n",
    "        X_train = np.vstack(train_features)\n",
    "        y_train = np.array(train_labels)\n",
    "\n",
    "        X_test = np.vstack(test_features)\n",
    "        y_test = np.array(test_labels)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)  \n",
    "        X_test_scaled = scaler.transform(X_test)  \n",
    "    \n",
    "        pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "        X_train_reduced = pca.fit_transform(X_train_scaled)\n",
    "        X_test_reduced = pca.transform(X_test_scaled)\n",
    "\n",
    "        # train svm \n",
    "        svm = SVC(**config, random_state=42)\n",
    "        svm.fit(X_train_reduced, y_train)\n",
    "\n",
    "        # evaluate \n",
    "        y_pred = svm.predict(X_test_reduced)\n",
    "        \n",
    "        epoch_accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Fold {fold + 1} Epoch-Level Accuracy: {epoch_accuracy:.2f}\")\n",
    "\n",
    "        epoch_correct = sum(y_test == y_pred) \n",
    "        fold_total_epochs = len(y_test)       \n",
    "        total_correct_epochs += epoch_correct\n",
    "        total_epochs += fold_total_epochs\n",
    "        # Majority voting for session-level prediction, predicts if each epoch is SD or NS \n",
    "        session_predictions = []\n",
    "        session_labels = []\n",
    "        start_idx = 0\n",
    "        for data in test_patient_data:\n",
    "            num_epochs = data[\"features\"].shape[0]\n",
    "            session_pred = y_pred[start_idx:start_idx + num_epochs]\n",
    "            session_label = data[\"label\"]\n",
    "            majority_label = Counter(session_pred).most_common(1)[0][0]  \n",
    "            session_predictions.append(majority_label)\n",
    "            session_labels.append(session_label)\n",
    "            start_idx += num_epochs\n",
    "\n",
    "        session_accuracy = accuracy_score(session_labels, session_predictions)\n",
    "        correct_sessions = sum(np.array(session_labels) == np.array(session_predictions))\n",
    "        fold_total_sessions = len(session_labels)\n",
    "        print(f\"Fold {fold + 1} Session-Level Accuracy: {session_accuracy:.2f}\")\n",
    "        total_correct_sessions += correct_sessions\n",
    "\n",
    "        print(\"Session-Level Classification Report:\")\n",
    "        print(classification_report(session_labels, session_predictions))\n",
    "\n",
    "    overall_epoch_accuracy = total_correct_epochs / total_epochs\n",
    "    overall_session_accuracy = total_correct_sessions / total_sessions\n",
    "\n",
    "    print(f\"\\nOverall Epoch-Level Accuracy: {overall_epoch_accuracy:.2f}\")\n",
    "    print(f\"Total Correct Predictions (Epoch-Level): {total_correct_epochs}/{total_epochs}\")\n",
    "    print(f\"\\nOverall Session-Level Accuracy: {overall_session_accuracy:.2f}\")\n",
    "    print(f\"Total Correct Predictions (Session-Level): {total_correct_sessions}/{total_sessions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get PSD for raw and smoothed signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "psd_raw = []\n",
    "fmin, fmax = 2, 40  # Hz\n",
    "\n",
    "for i in range(1, 72):\n",
    "    patient_id = f\"sub-{i:02d}\"\n",
    "    for session, condition in zip(['1', '2'], ['normal sleep', 'sleep deprivation']):\n",
    "        eeg_path = os.path.join(\"Sleep_dep_dataset\", patient_id, \"ses-\" + session, \"eeg\", patient_id + \"_ses-\" + session + \"_task-eyesopen_eeg.set\")\n",
    "        \n",
    "        if os.path.exists(eeg_path):\n",
    "            raw = mne.io.read_raw_eeglab(eeg_path, preload=True)\n",
    "            data = raw.get_data()\n",
    "            freqs, psd = welch(data, sfreq, nperseg=sfreq * 2, axis=1)\n",
    "            freq_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "            freqs_filtered = freqs[freq_mask]\n",
    "            psd_filtered = psd[:, freq_mask]\n",
    "            mean_psd = np.mean(psd_filtered, axis=0)  \n",
    "            psd_raw.append(mean_psd)\n",
    "           \n",
    "psd_raw = np.array(psd_raw)\n",
    "mean_raw = np.mean(psd_raw, axis=0)\n",
    "sem_raw = np.std(psd_raw, axis=0) / np.sqrt(psd_raw.shape[0])\n",
    "\n",
    "\n",
    "#SMOOTHED SIGNAL PSD\n",
    "features_file = \"KF_smoothed_data.pkl\"\n",
    "with open(features_file, 'rb') as f:\n",
    "    smoothed_data_dict = pickle.load(f)\n",
    "psd_smoothed = [] \n",
    "sfreq = 500\n",
    "for patient_session, data in smoothed_data_dict.items():\n",
    "    smoothed_data = data['smoothed_data'] \n",
    "\n",
    "    smoothed_data_continuous = np.concatenate(smoothed_data, axis=-1)  \n",
    "\n",
    "    freqs, psd = welch(smoothed_data_continuous, sfreq, nperseg=sfreq * 2, axis=1) \n",
    "    freq_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "    freqs_filtered = freqs[freq_mask]\n",
    "    psd_filtered = psd[:, freq_mask]\n",
    "    mean_psd = np.mean(psd_filtered, axis=0) \n",
    "    psd_smoothed.append(mean_psd)\n",
    "\n",
    "#\n",
    "psd_smoothed = np.array(psd_smoothed)\n",
    "mean_smoothed = np.mean(psd_smoothed, axis=0)\n",
    "sem_smoothed = np.std(psd_smoothed, axis=0) / np.sqrt(psd_smoothed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Convert PSD values to dB\n",
    "mean_smoothed_db = 10 * np.log10(mean_smoothed)\n",
    "sem_smoothed_db = 10 * np.log10(mean_smoothed + sem_smoothed) - mean_smoothed_db\n",
    "\n",
    "mean_raw_db = 10 * np.log10(mean_raw)\n",
    "sem_raw_db = 10 * np.log10(mean_raw + sem_raw) - mean_raw_db\n",
    "\n",
    "# Plotting the smoothed signal\n",
    "plt.plot(freqs_filtered, mean_smoothed_db, label='KF Smoothed Signal', color='blue')\n",
    "plt.fill_between(\n",
    "    freqs_filtered, \n",
    "    mean_smoothed_db - sem_smoothed_db, \n",
    "    mean_smoothed_db + sem_smoothed_db, \n",
    "    alpha=0.2, \n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "# Plotting the original signal\n",
    "plt.plot(freqs_filtered, mean_raw_db, label='Original Signal', color='orange')\n",
    "plt.fill_between(\n",
    "    freqs_filtered, \n",
    "    mean_raw_db - sem_raw_db, \n",
    "    mean_raw_db + sem_raw_db, \n",
    "    alpha=0.2, \n",
    "    color='orange'\n",
    ")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD (dB)')  # Updated units\n",
    "plt.title('KF Smoothed Signal vs Original Signal (PSD in dB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_raw_ns = []\n",
    "psd_raw_sd = []\n",
    "for i in range(1, 72):\n",
    "    patient_id = f\"sub-{i:02d}\"\n",
    "    for session, condition in zip(['1', '2'], ['normal sleep', 'sleep deprivation']):\n",
    "        eeg_path = os.path.join(\"Sleep_dep_dataset\", patient_id, \"ses-\" + session, \"eeg\", patient_id + \"_ses-\" + session + \"_task-eyesopen_eeg.set\")\n",
    "        \n",
    "        if os.path.exists(eeg_path):\n",
    "            raw = mne.io.read_raw_eeglab(eeg_path, preload=True)\n",
    "            data = raw.get_data()\n",
    "\n",
    "            freqs, psd = welch(data, sfreq, nperseg=sfreq * 2, axis=1)\n",
    "            freq_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "            freqs_filtered = freqs[freq_mask]\n",
    "            psd_filtered = psd[:, freq_mask]\n",
    "            mean_psd = np.mean(psd_filtered, axis=0)\n",
    "  \n",
    "            if condition == 'normal sleep':\n",
    "                psd_raw_ns.append(mean_psd)\n",
    "            else:\n",
    "                psd_raw_sd.append(mean_psd)\n",
    "\n",
    "psd_raw_ns = np.array(psd_raw_ns)\n",
    "psd_raw_sd = np.array(psd_raw_sd)\n",
    "\n",
    "mean_raw_ns = np.mean(psd_raw_ns, axis=0)\n",
    "sem_raw_ns = np.std(psd_raw_ns, axis=0) / np.sqrt(psd_raw_ns.shape[0])\n",
    "\n",
    "mean_raw_sd = np.mean(psd_raw_sd, axis=0)\n",
    "sem_raw_sd = np.std(psd_raw_sd, axis=0) / np.sqrt(psd_raw_sd.shape[0])\n",
    "\n",
    "psd_smoothed_ns = []\n",
    "psd_smoothed_sd = []\n",
    "\n",
    "features_file = \"KF_smoothed_data.pkl\"\n",
    "with open(features_file, 'rb') as f:\n",
    "    smoothed_data_dict = pickle.load(f)\n",
    "\n",
    "for patient_session, data in smoothed_data_dict.items():\n",
    "    smoothed_data = data['smoothed_data'] \n",
    "    label = data['label']  \n",
    "\n",
    "\n",
    "    smoothed_data_continuous = np.concatenate(smoothed_data, axis=-1)  \n",
    "\n",
    "  \n",
    "    freqs, psd = welch(smoothed_data_continuous, sfreq, nperseg=sfreq * 2, axis=1)  \n",
    "    freq_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "    freqs_filtered = freqs[freq_mask]\n",
    "    psd_filtered = psd[:, freq_mask]\n",
    "    mean_psd = np.mean(psd_filtered, axis=0)\n",
    "    \n",
    "    if label == 0:  \n",
    "        psd_smoothed_ns.append(mean_psd)\n",
    "    else:  \n",
    "        psd_smoothed_sd.append(mean_psd)\n",
    "\n",
    "psd_smoothed_ns = np.array(psd_smoothed_ns)\n",
    "psd_smoothed_sd = np.array(psd_smoothed_sd)\n",
    "\n",
    "mean_smoothed_ns = np.mean(psd_smoothed_ns, axis=0)\n",
    "sem_smoothed_ns = np.std(psd_smoothed_ns, axis=0) / np.sqrt(psd_smoothed_ns.shape[0])\n",
    "\n",
    "mean_smoothed_sd = np.mean(psd_smoothed_sd, axis=0)\n",
    "sem_smoothed_sd = np.std(psd_smoothed_sd, axis=0) / np.sqrt(psd_smoothed_sd.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert PSD values to dB for smoothed signals\n",
    "mean_smoothed_ns_db = 10 * np.log10(mean_smoothed_ns)\n",
    "sem_smoothed_ns_db = 10 * np.log10(mean_smoothed_ns + sem_smoothed_ns) - mean_smoothed_ns_db\n",
    "\n",
    "mean_smoothed_sd_db = 10 * np.log10(mean_smoothed_sd)\n",
    "sem_smoothed_sd_db = 10 * np.log10(mean_smoothed_sd + sem_smoothed_sd) - mean_smoothed_sd_db\n",
    "\n",
    "# Convert PSD values to dB for raw signals\n",
    "mean_raw_ns_db = 10 * np.log10(mean_raw_ns)\n",
    "sem_raw_ns_db = 10 * np.log10(mean_raw_ns + sem_raw_ns) - mean_raw_ns_db\n",
    "\n",
    "mean_raw_sd_db = 10 * np.log10(mean_raw_sd)\n",
    "sem_raw_sd_db = 10 * np.log10(mean_raw_sd + sem_raw_sd) - mean_raw_sd_db\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Smoothed signals plot\n",
    "axes[0].plot(freqs_filtered, mean_smoothed_ns_db, label='NS (Smoothed)', color='blue')\n",
    "axes[0].fill_between(\n",
    "    freqs_filtered,\n",
    "    mean_smoothed_ns_db - sem_smoothed_ns_db,\n",
    "    mean_smoothed_ns_db + sem_smoothed_ns_db,\n",
    "    alpha=0.2,\n",
    "    color='blue'\n",
    ")\n",
    "axes[0].plot(freqs_filtered, mean_smoothed_sd_db, label='SD (Smoothed)', color='orange')\n",
    "axes[0].fill_between(\n",
    "    freqs_filtered,\n",
    "    mean_smoothed_sd_db - sem_smoothed_sd_db,\n",
    "    mean_smoothed_sd_db + sem_smoothed_sd_db,\n",
    "    alpha=0.2,\n",
    "    color='orange'\n",
    ")\n",
    "axes[0].set_title('Smoothed Signal: NS vs SD')\n",
    "axes[0].set_xlabel('Frequency (Hz)')\n",
    "axes[0].set_ylabel('PSD (dB)')  # Updated units\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Raw signals plot\n",
    "axes[1].plot(freqs_filtered, mean_raw_ns_db, label='NS (Raw)', color='blue')\n",
    "axes[1].fill_between(\n",
    "    freqs_filtered,\n",
    "    mean_raw_ns_db - sem_raw_ns_db,\n",
    "    mean_raw_ns_db + sem_raw_ns_db,\n",
    "    alpha=0.2,\n",
    "    color='blue'\n",
    ")\n",
    "axes[1].plot(freqs_filtered, mean_raw_sd_db, label='SD (Raw)', color='orange')\n",
    "axes[1].fill_between(\n",
    "    freqs_filtered,\n",
    "    mean_raw_sd_db - sem_raw_sd_db,\n",
    "    mean_raw_sd_db + sem_raw_sd_db,\n",
    "    alpha=0.2,\n",
    "    color='orange'\n",
    ")\n",
    "axes[1].set_title('Raw Signal: NS vs SD')\n",
    "axes[1].set_xlabel('Frequency (Hz)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
